{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SpamCommentsModelMaker.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5ITO338mNQE"
      },
      "source": [
        "# Welcome to this colab for Creating a comment spam classifier!\n",
        "In this colab, you'll go through code that uses data that we've prepared\n",
        "for you from thousands of YouTube comments. We've tidied up the text\n",
        "and put it in a CSV file so it's ready to go. It will train a classifier from\n",
        "this text in just a few minutes, while abstracting a lot of the difficult\n",
        "details of building Natural Language Processing models into a simple library.\n",
        "We've also provided guidance for how you can fine tune the model should you want to do so.\n",
        "\n",
        "The first two cells here are hidden code. You can unhide them to see what they do, or you can just run them! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awq8sMaIFHJ1",
        "cellView": "form"
      },
      "source": [
        "#@title Run to install (It is safe to ignore a tensorflowjs 3.2.0 error if you see it)\n",
        "# Install Model maker\n",
        "!pip install -q tflite-model-maker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fEAqoLLF6O9",
        "cellView": "form"
      },
      "source": [
        "#@title Run to import required libraries\n",
        "# Imports and check that we are using TF2.x\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker import configs\n",
        "from tflite_model_maker import ExportFormat\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import text_classifier\n",
        "from tflite_model_maker import TextClassifierDataLoader\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsuDZvjgREsS"
      },
      "source": [
        "# This will download the training data from the given URL\n",
        "# you can use any CSV file for your data as long as it has a column\n",
        "# with text that you want to train on, and another with the label.\n",
        "# The columns should be defined in the first line of the CSV file\n",
        "training_data = tf.keras.utils.get_file(fname='cleaned_youtube.csv', origin='https://storage.googleapis.com/laurencemoroney-blog.appspot.com/cleaned_youtube.csv', extract=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E59qhuMyS-Yd"
      },
      "source": [
        "# This will take the downloaded CSV file, and create a pointer to the local\n",
        "# file so we can train with it later\n",
        "training_data = os.path.join(os.path.dirname(training_data), 'cleaned_youtube.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbew43TbG9HQ"
      },
      "source": [
        "# Use a model spec from model maker. Options are 'mobilebert_classifier', 'bert_classifier' and 'average_word_vec'\n",
        "# The first 2 use the BERT model, which is accurate, but larger and slower to train\n",
        "# Average Word Vec is kinda like transfer learning where there are pre-trained word weights\n",
        "# and dictionaries.\n",
        "spec = model_spec.get('average_word_vec')\n",
        "\n",
        "# The num_words parameter is the number of words in the corpus you want to train with\n",
        "# This will be the top 2000 words by frequency of that word being present in all the text\n",
        "# A nice way to fine tune your model is to tweak this. Too big, and the model will be trained\n",
        "# using words that almost never show up. Too small, and the model will miss out on some important\n",
        "# words. Feel free to experiment with this value\n",
        "spec.num_words = 2000\n",
        "\n",
        "# When training a natural language processing model, the underlying engine will convert\n",
        "# words into tokens. Sentences are then sequences of tokens. So all sentences being fed\n",
        "# into the model will need to be a sequence of tokens, and these all have to be the same\n",
        "# length. Here we set it to 20, so sentences of more than 20 words will be truncated, and\n",
        "# sentences of less will be padded. Choose this number carefully based on the length of\n",
        "# sentences in your training data, and the expected length of sentences sent by users\n",
        "spec.seq_len = 20\n",
        "\n",
        "# As you study NLP, you'll learn about Word Embeddings, which are vectors that denote a 'direction' \n",
        "# for a word. These vectors are used to establish sentiment. In a simple sense, think about 'true' pointing left\n",
        "# and 'false' pointing right. Here, from direction, you can establish sentiment. When you have\n",
        "# thousands of words, you need more dimensions. Research has shown that the best starting point\n",
        "# for the number of dimensions is the fourth root of the number of words. Given we are using \n",
        "# 2000 words, the fourth root of which is 6.68. I have rounded that up to 7 here\n",
        "spec.wordvec_dim = 7\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WdQmzTKHFVn"
      },
      "source": [
        "# Load the CSV using DataLoader.from_csv to make the training_data\n",
        "# The important things to note are the text_column and the label_column. \n",
        "# These should be present in the first row of your file\n",
        "# So, your CSV should look something like this\n",
        "# commenttext, spam\n",
        "# text for the comment, true\n",
        "# text for another comment, true\n",
        "# text for yet another comment, false\n",
        "train_data = TextClassifierDataLoader.from_csv(\n",
        "      filename=os.path.join(os.path.join(training_data)),\n",
        "      text_column='commenttext', #For Toxicity use \" value_of_text\" (note the leading space)\n",
        "      label_column='spam', #For Toxicity also use \"label\"\n",
        "      model_spec=spec,\n",
        "      delimiter=',',\n",
        "      is_training=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qThBoIIyG_Du"
      },
      "source": [
        "# Build the model\n",
        "# All of the model architecture is abstracted within this\n",
        "# With 100 epochs it trains to 97%+ accuracy. You can tweak this value\n",
        "# to speed up the training, but it's already quite fast!\n",
        "model = text_classifier.create(train_data, model_spec=spec, epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In-1-rzW-_9b"
      },
      "source": [
        "# Export the model as a TFLITE file to use in Android or iOS\n",
        "model.export(export_dir='/mm_spam')\n",
        "\n",
        "# If you are an iOS developer, you'll also need the labels and vocab, so you can export them like this\n",
        "model.export(export_dir='/mm_spam/', export_format=[ExportFormat.LABEL, ExportFormat.VOCAB])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe8l3arWnvlZ"
      },
      "source": [
        "# Downloading the model\n",
        "In the previous code section, you exported the model to a directory called /mm_spam.\n",
        "\n",
        "On the left side of colab, there are 4 icons: a list, a magnifying glass, brackets, and a folder. Click the folder.\n",
        "\n",
        "This gives you access to the directory structure of the virtual machine running your code in the cloud.\n",
        "\n",
        "Click the folder with the up arrow to go to the root directory.\n",
        "\n",
        "You'll get a listing of all directories, including the mm_spam directory.\n",
        "\n",
        "Open it, and you'll see a file called 'model.tflite'. Click on this to download it to use it in an Android or iOS app. If you also exported the labels and vocab file, you'll see labels.txt and vocab. You'll need to download these, too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWuiOWbR_Omp"
      },
      "source": [
        "# Optionally you can shrink and quantize the model prior to exporting\n",
        "# This makes the model smaller, and possibly slightly less efficient\n",
        "config = configs.QuantizationConfig.create_dynamic_range_quantization(optimizations=[tf.lite.Optimize.OPTIMIZE_FOR_LATENCY])\n",
        "config.experimental_new_quantizer = True\n",
        "model.export(export_dir='/mm_spam/', quantization_config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-eH34EUQ1tR"
      },
      "source": [
        "# At this point you're done! But if you want to explore the neural network\n",
        "# architecture of the model, you could do this:\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW5vfrLHTDM8"
      },
      "source": [
        "# And if you want to export to a JSON-formatted model to make for easier loading\n",
        "# into TensorFlow.js you can do this\n",
        "model.export(export_dir=\"/mm_js/\", export_format=[ExportFormat.TFJS, ExportFormat.LABEL, ExportFormat.VOCAB])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}